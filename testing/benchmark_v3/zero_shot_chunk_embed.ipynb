{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acdb4c73",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Chunk all text and check if similar chunks are together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe110be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "problemset_df = pd.read_csv(\"C:\\\\Users\\\\mokrota\\\\Documents\\\\GitHub\\\\math_problem_recommender\\\\math_problem_recommender\\\\benchmark\\\\benchmarkv3\\\\df.csv\")\n",
    "problemset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572b7789",
   "metadata": {},
   "source": [
    "## Testing on small head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = problemset_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from similarity import BERTCLSMeanPooler, EmbSummarizer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = \"math-similarity/Bert-MLM_arXiv-MP-class_zbMath\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_maping(inputs):\n",
    "    maping = inputs['offset_mapping']\n",
    "    chunks = []\n",
    "    for chunk in maping:\n",
    "        start = None\n",
    "        end = None\n",
    "        for token in chunk:\n",
    "            token_item = token.tolist()\n",
    "            if token_item == [0, 0]:\n",
    "                continue\n",
    "            if start is None:\n",
    "                start = token_item[0]\n",
    "                break\n",
    "        for token in chunk.flip(0):\n",
    "            token_item = token.tolist()\n",
    "            if token_item == [0, 0]:\n",
    "                continue\n",
    "            if end is None:\n",
    "                end = token_item[1]\n",
    "                break\n",
    "        chunks.append((start, end))\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a76d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def chunk_util(row, col_name, summarizer: EmbSummarizer):\n",
    "    col = row[col_name]\n",
    "    inputs = summarizer.tokenize(col)\n",
    "    emb = summarizer.embed(inputs).last_hidden_state\n",
    "    emb_serialized = [pickle.dumps(emb[i]) for i in range(emb.shape[0])]\n",
    "    chunks_map = chunk_maping(inputs)\n",
    "    return {\n",
    "        \"embeddings_pickle\": emb_serialized,\n",
    "        \"chunk_maping\": chunks_map,\n",
    "        \"embeddings\": emb\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c484ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = BERTCLSMeanPooler(model, tokenizer, **{\"return_offsets_mapping\": True, \"max_length\": 128})\n",
    "\n",
    "new_column = small_df.apply(lambda row: chunk_util(row, \"Problem\", summarizer), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0433e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([small_df, new_column], axis=1)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef04d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_df_with_emb.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_df, f)\n",
    "\n",
    "with open(\"test_df_with_emb.pkl\", \"rb\") as f:\n",
    "    df_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b1e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "emb_pickle_list = df_loaded['embeddings_pickle'].tolist()\n",
    "emb = df_loaded['embeddings'].tolist()\n",
    "emb_list = [[pickle.loads(c) for c in emb] for emb in emb_pickle_list]\n",
    "any_wrong = False\n",
    "for e1, e2 in zip(emb, emb_list):\n",
    "    for c1, c2 in zip(e1, e2):\n",
    "        if not torch.allclose(c1, c2, atol=1e-10):\n",
    "            print(f\"Not equal:\\n\\n{e1}\\n\\nand\\n\\n{e2}\\n\\n\")\n",
    "            any_wrong = True\n",
    "\n",
    "if not any_wrong:\n",
    "    print(\"All equal!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_util(row, col_name, summarizer: EmbSummarizer):\n",
    "    col = row[col_name]\n",
    "    inputs = summarizer.tokenize(col)\n",
    "    emb = summarizer.embed(inputs).last_hidden_state\n",
    "    emb_serialized = [pickle.dumps(emb[i]) for i in range(emb.shape[0])]\n",
    "    chunks_map = chunk_maping(inputs)\n",
    "    return {\n",
    "        \"embeddings_pickle\": emb_serialized,\n",
    "        \"chunk_maping\": chunks_map\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dbd7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_explode_df(df: pd.DataFrame, col_name, summarizer):\n",
    "    new_column = df.apply(lambda row: chunk_util(row, col_name, summarizer), axis=1, result_type='expand')\n",
    "    df = pd.concat([df, new_column], axis=1)\n",
    "    df = df.rename({\"id\": \"parent_id\"}, axis=1)\n",
    "    df = df.explode(['embeddings_pickle', 'chunk_maping'], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d25535",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_emb_df = chunk_explode_df(small_df, \"Problem\", summarizer)\n",
    "sol_emb_df = chunk_explode_df(small_df, \"Solution\", summarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bf011",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_emb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_emb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6d484",
   "metadata": {},
   "source": [
    "## Doing for the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c973d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_emb_df = chunk_explode_df(problemset_df, \"Problem\", summarizer)\n",
    "sol_emb_df = chunk_explode_df(problemset_df, \"Solution\", summarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca48152",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_emb_df = p_emb_df[[\"parent_id\", \"Problem\", \"Problem Book No\", \"TopicMetadata\", \"embeddings_pickle\", \"chunk_maping\"]]\n",
    "p_emb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d58e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_emb_df = sol_emb_df[[\"parent_id\", \"Solution\", \"Problem Book No\", \"TopicMetadata\", \"embeddings_pickle\", \"chunk_maping\"]]\n",
    "sol_emb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec754900",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"problem_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(p_emb_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"solution_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sol_emb_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"solution_embeddings.pkl\", \"rb\") as f:\n",
    "    df_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b9d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [pickle.loads(e) for e in df_loaded['embeddings_pickle'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea517d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e44b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_embeddings = [e[0] for e in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f84624",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_embeddings = torch.stack(cls_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaaa739",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99acf0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = \"Find problems that use divisibility to limit number of options.\"\n",
    "anchor_emb = summarizer.summarize(anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d31032",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca2ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from similarity import CosineSimScorer\n",
    "\n",
    "ranker = CosineSimScorer()\n",
    "ranks = ranker.rank(anchor_emb, cls_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ecb2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check = ranks[0:10].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df_loaded.loc[to_check]\n",
    "chunks_ids = sub_df['chunk_maping'].tolist()\n",
    "solutions = sub_df['Solution'].tolist()\n",
    "chunks = []\n",
    "for i in range(len(solutions)):\n",
    "    sol = solutions[i]\n",
    "    ids = chunks_ids[i]\n",
    "    chunk = sol[ids[0]:ids[1]]\n",
    "    chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ccdbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10357f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, s in zip(chunks, solutions):\n",
    "    print(\"Solution:\", s)\n",
    "    print()\n",
    "    print(\"Chunk:\", c)\n",
    "    print('-' * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
